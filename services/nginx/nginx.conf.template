error_log log/error.log error;
pid run/nginx.pid;

# Choose number of NGINX worker processes based on number of CPUs
worker_processes auto;

http {
  sendfile on;
  tcp_nopush on;
  types_hash_max_size 4096;

  # Enable compression of outgoing data
  gzip on;
  gzip_min_length 1000;
  gzip_proxied any;
  gzip_types text/plain
             text/css
             application/json
             application/x-javascript
             application/xml
             text/javascript
             application/javascript;

  # Only retry if there was a communication error, not a timeout
  # on the Tornado server (to avoid propagating "queries of death"
  # to all frontends)
  #
  # See https://www.tornadoweb.org/en/stable/guide/running.html
  proxy_next_upstream error;

  {% for ip in server.loadbalancer_ips -%}
    set_real_ip_from {{ ip }};
  {% endfor %}
  real_ip_header X-Forwarded-For;
  real_ip_recursive on;

  geo $limit {
    default 1;
    127.0.0.1/32 0;
    {% for ip in server.whitelisted_ips -%}
      {{ ip }} 0;
    {% endfor %}
  }

  map $limit $limit_key {
    0 "";
    1 $http_authorization;
  }

  # Per-token API rate limiting
  limit_req_zone $limit_key zone=custom_rate_limit:1m rate={{ server.rate_limit }}r/s;

  upstream websocket_server {
    server localhost:{{ ports.websocket }};
  }

  upstream fakeoauth_server {
    server localhost:{{ ports.fake_oauth }};
  }

  upstream frontend {
    least_conn;
    {% for p in range(server.processes) -%}
      server 127.0.0.1:{{ ports.app_internal + p }} fail_timeout={{ server.fail_timeout }}s;
    {% endfor %}
    server 127.0.0.1:{{ ports.status }} backup max_fails=0;
  }

  # Only a subset of processes are available for token authenticated API
  # requests.  This ensures that even when the system is being
  # hit by API requests, the frontend remains responsive.
  upstream api {
    least_conn;
    {% for p in range(server.dedicated_frontend_processes, [server.processes, server.dedicated_frontend_processes + 1] | max) -%}
      server 127.0.0.1:{{ ports.app_internal + p }} fail_timeout={{ server.fail_timeout }}s;
    {% endfor %}
    server 127.0.0.1:{{ ports.status }} backup max_fails=0;
  }

  # See http://nginx.org/en/docs/http/websocket.html
  map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
  }

  map $http_authorization $pool {
    default frontend;
    '~.' api;
  }

  map $request_method $exclude_head_requests {
    HEAD    0;
    default 1;
  }

  map $status $loggable {
      ~^[2]   $exclude_head_requests;
      ~^[3]   0;
      ~^[101] 0;
      404     $exclude_head_requests;
      default 1;
  }

  map $http_authorization $trunc_authorization {
    default "";
    "~*(?P<tr>.{0,14}).*" $tr;
  }

  log_format elb_log '$remote_addr - $remote_user [$trunc_authorization] [$time_local] ' '"$request" $status $body_bytes_sent rl=$request_length "$http_referer" ' '"$http_user_agent"';

  server {
    {% if env.debug %}
    listen 127.0.0.1:{{ ports.app }};
    {% else %}
    {% if server.ssl_certificate %}
    listen {{ ports.app }} ssl;
    {% else %}
    listen {{ ports.app }};
    {% endif %}
    listen {{ ports.app_http_proxy }} proxy_protocol; # This is for AWS Elastic Load Balancer
    {% endif %}
    client_max_body_size {{ server.max_body_size }}M;

    {% if server.ssl_certificate %}
    ssl_certificate {{ server.ssl_certificate }};
    ssl_certificate_key {{ server.ssl_certificate_key }};
    {% endif %}

    location / {
      # API rate limiting
      limit_req zone=custom_rate_limit burst={{ server.burst }} nodelay;
      limit_req_status 429;

      proxy_pass http://$pool;

      proxy_set_header Host $http_host;
      proxy_set_header X-Real-IP $remote_addr;
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      proxy_set_header X-Forwarded-Proto $scheme;

      # Buffer sizes; see
      # https://www.getpagespeed.com/server-setup/nginx/tuning-proxy_buffer_size-in-nginx

      # Handle uploads up to 64k before buffering to disk
      client_body_buffer_size 64k;

      # Buffer responses up to 256k
      proxy_buffers 32 8k;

      # Serve static files directly
      location /static/ {
        root .;
        include mime.types;
        if ($query_string) {
          expires max;
        }
      }
      location /favicon.png {
        root static;
        expires max;
      }
    }

    location /websocket {
        proxy_pass http://websocket_server/websocket;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection $connection_upgrade;
        proxy_read_timeout 60s;
    }

    location /fakeoauth2 {
        proxy_pass http://fakeoauth_server/fakeoauth2;
    }

    error_log log/nginx-error.log warn;
    # one of: debug, info, notice, warn, error, crit, alert, emerg

{% if log.api_calls %}
    {% set log_cond = "" %}
{% else %}
    {% set log_cond = "if=$loggable" %}
{% endif %}
    access_log log/nginx-access.log elb_log {{ log_cond }};
  }

  # Set an array of temp and cache file options that will otherwise default to
  # restricted locations accessible only to root.
  client_body_temp_path tmp/client_body;
  fastcgi_temp_path tmp/fastcgi_temp;
  proxy_temp_path tmp/proxy_temp;
  scgi_temp_path tmp/scgi_temp;
  uwsgi_temp_path tmp/uwsgi_temp;

}

events {
  worker_connections 1024;
}
